# -*- coding: utf-8 -*-
"""predictemotionspreprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lFLk0VAU0-SRKbKUcxNmXWmMu9wnaoDY
"""

import openpyxl
import string
import nltk

# Download the stopwords list from NLTK
nltk.download('stopwords')

# Open the workbook
wb = openpyxl.load_workbook('/content/duygular.xlsx')

# Select the sheet
sheet = wb['Sayfa1']

# Get the English stopwords list
stopwords = nltk.corpus.stopwords.words('turkish')

# Loop through the rows of the sheet
for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row, min_col=1, max_col=2):
    # Read the tweet text and result from the cells
    tweet_text = row[0].value
    result = row[1].value

    # Remove stopwords and convert to lowercase
    if isinstance(tweet_text, str):
        tweet_text_clean = [word for word in tweet_text.split() if word.lower() not in stopwords]
        tweet_text_clean = ' '.join(tweet_text_clean).lower()
    else:
        tweet_text_clean = tweet_text

    if isinstance(result, str):
        result_clean = [word for word in result.split() if word.lower() not in stopwords]
        result_clean = ' '.join(result_clean).lower()
    else:
        result_clean = result

    # Write the cleaned text and result back to the cells
    row[0].value = tweet_text_clean
    row[1].value = result_clean

# Save the workbook to a different file
wb.save('/content/duygularstopwordlowercase.xlsx')



import pandas as pd

def excel_den_veri_setini_yukle(dosya_yolu, sayfa_adi, sutun_adlari):
    # Dosyayı oku
    veri_seti_df = pd.read_excel(dosya_yolu, sheet_name=sayfa_adi)

    # İlgili sütunlardaki metinleri birleştir
    veri_seti = ' '.join(veri_seti_df[sutun_adlari].astype(str))

    return veri_seti

# Örnek kullanım:
dosya_yolu_excel = '/content/duygularstopwordlowercase.xlsx'
sayfa_adi_excel = 'Sayfa1'
sutun_adlari_excel = ['comments']

duygu_veri_seti_excel = excel_den_veri_setini_yukle(dosya_yolu_excel, sayfa_adi_excel, sutun_adlari_excel)

# Save the workbook to a different file
wb.save('/content/duygularstopwordlowercasegereksizkarekter.xlsx')



!pip install regex

import pandas as pd
import regex

def emojileri_kaldir_excel(dosya_yolu, sayfa_adi, sutun_adlari):
    # Excel dosyasını oku
    veri_seti_df = pd.read_excel(dosya_yolu, sheet_name=sayfa_adi)

    # Belirtilen sütunlardaki metinlerden emojileri kaldır
    for sutun_adi in sutun_adlari:
        veri_seti_df[sutun_adi] = veri_seti_df[sutun_adi].astype(str).apply(emojileri_kaldir)

    return veri_seti_df

def emojileri_kaldir(metin):
    # Emoji Unicode karakterlerini kaldır
    temizlenmis_metin = regex.sub(r'\p{So}+', '', metin)
    return temizlenmis_metin

# Örnek kullanım:
dosya_yolu_excel = '/content/duygularstopwordlowercasegereksizkarekter.xlsx'
sayfa_adi_excel = 'Sayfa1'
sutun_adlari_excel = ['comments']

# Excel dosyasındaki emojileri kaldır
duygu_veri_seti_temiz = emojileri_kaldir_excel(dosya_yolu_excel, sayfa_adi_excel, sutun_adlari_excel)

# Veriyi yeni bir Excel dosyasına kaydet
duygu_veri_seti_temiz.to_excel('/content/duygularstopwordlowercasegereksizkarekteremojikaldir.xlsx', index=False)



from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
import pandas as pd

# Veri setini okuma
excel_dosya_adı = '/content/duygularstopwordlowercasegereksizkarekteremojikaldir.xlsx'  # Veri setinizin dosya adını güncelleyin
veri_seti = pd.read_excel(excel_dosya_adı)

# Metin ve etiketleri ayırma
X = veri_seti['comments']
y = veri_seti['label']

# Tokenization için tokenizer'ı oluştur
max_kelime_sayısı = 10000
tokenizer = Tokenizer(num_words=max_kelime_sayısı)
tokenizer.fit_on_texts(X)

# Metin verilerini sayısal dizilere dönüştürme
tokenized_metinler = tokenizer.texts_to_sequences(X)

max_dizgi_uzunlugu = 100
padded_metinler = pad_sequences(tokenized_metinler, maxlen=max_dizgi_uzunlugu, padding='post', truncating='post')

# Tokenizer'ın kelime indeksini alma
kelime_indeks = tokenizer.word_index



kelime_indeksi_df = pd.DataFrame(list(kelime_indeks.items()), columns=['Kelime', 'İndeks'])
kelime_indeksi_df.to_excel('/content/duygularstopwordlowercasegereksizkarekteremojikaldirtoken2.xlsx', index=False)

!pip install numpy pandas tensorflow













